{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Char_Level_Lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbe7NYX1FOja"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n6bhLF8FuZw"
      },
      "source": [
        "with open(\"anna.txt\", \"r\") as f:\n",
        "  text = f.read()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sj30JLN0GFFi",
        "outputId": "1149eb15-b6df-49b0-cac0-f41094805ace"
      },
      "source": [
        "text[:100]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Chapter 1\\n\\n\\nHappy families are all alike; every unhappy family is unhappy in its own\\nway.\\n\\nEverythin'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM1N8MklGIn0"
      },
      "source": [
        "chars = tuple(set(text))\n",
        "\n",
        "int2char = dict(enumerate(chars))\n",
        "\n",
        "char2int = {ch: ii for ii, ch in int2char.items()}\n",
        "\n",
        "encoded = np.array([char2int[ch] for ch in text])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jze9ZgImGazl",
        "outputId": "30a9123d-cac1-4277-b047-77356e4553a4"
      },
      "source": [
        "encoded[:100]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([81,  4, 12, 25, 41, 32, 66, 20,  1, 45, 45, 45, 80, 12, 25, 25, 74,\n",
              "       20, 82, 12, 71, 61, 56, 61, 32, 28, 20, 12, 66, 32, 20, 12, 56, 56,\n",
              "       20, 12, 56, 61, 76, 32,  6, 20, 32, 24, 32, 66, 74, 20,  2,  3,  4,\n",
              "       12, 25, 25, 74, 20, 82, 12, 71, 61, 56, 74, 20, 61, 28, 20,  2,  3,\n",
              "        4, 12, 25, 25, 74, 20, 61,  3, 20, 61, 41, 28, 20, 38, 50,  3, 45,\n",
              "       50, 12, 74, 55, 45, 45, 21, 24, 32, 66, 74, 41,  4, 61,  3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfoiQUBpGdzl"
      },
      "source": [
        "def one_hot_encode(arr, n_labels):\n",
        "  one_hot = np.zeros((arr.size, n_labels), dtype = np.float32)\n",
        "\n",
        "  one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1\n",
        "\n",
        "  one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
        "\n",
        "  return one_hot"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_gTkUPeHAks",
        "outputId": "61347f72-cf9f-4804-c795-cb0405d7b092"
      },
      "source": [
        "test = np.array([[2, 3, 6]])\n",
        "\n",
        "print(one_hot_encode(test, 8))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 1. 0.]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CIzO7-6JelW"
      },
      "source": [
        "def get_batches(arr, batch_size, seq_length):\n",
        "  total_batch_size = batch_size * seq_length\n",
        "\n",
        "  n_batches = len(arr)//total_batch_size\n",
        "\n",
        "  arr = arr[:n_batches*total_batch_size]\n",
        "\n",
        "  arr = arr.reshape((batch_size, -1))\n",
        "\n",
        "  for n in range(0, arr.shape[1], seq_length):\n",
        "    x = arr[:,n : n+seq_length]\n",
        "\n",
        "    y = np.zeros_like(x)\n",
        "\n",
        "    try:\n",
        "      y[:,:-1], y[:, -1] = x[:,1:], arr[:,n+seq_length]\n",
        "    except IndexError:\n",
        "      y[:,:-1], y[:,-1] = x[:,1:], arr[:,0]\n",
        "    yield x, y"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0DkRpvvu_6j"
      },
      "source": [
        "batches = get_batches(encoded, 8, 50)\n",
        "\n",
        "x, y = next(batches)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtELNWBivJnn",
        "outputId": "d57ff27d-8165-44cc-a12e-0fbeba7cc3b6"
      },
      "source": [
        "print(f'x=> {x[:10,:10]}')\n",
        "print(f'y=> {y[:10,:10]}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x=> [[81  4 12 25 41 32 66 20  1 45]\n",
            " [28 38  3 20 41  4 12 41 20 12]\n",
            " [32  3 51 20 38 66 20 12 20 82]\n",
            " [28 20 41  4 32 20 53  4 61 32]\n",
            " [20 28 12 50 20  4 32 66 20 41]\n",
            " [53  2 28 28 61 38  3 20 12  3]\n",
            " [20 57  3  3 12 20  4 12 51 20]\n",
            " [36 65 56 38  3 28 76 74 55 20]]\n",
            "y=> [[ 4 12 25 41 32 66 20  1 45 45]\n",
            " [38  3 20 41  4 12 41 20 12 41]\n",
            " [ 3 51 20 38 66 20 12 20 82 38]\n",
            " [20 41  4 32 20 53  4 61 32 82]\n",
            " [28 12 50 20  4 32 66 20 41 32]\n",
            " [ 2 28 28 61 38  3 20 12  3 51]\n",
            " [57  3  3 12 20  4 12 51 20 28]\n",
            " [65 56 38  3 28 76 74 55 20 40]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsTcLCOXvQJY",
        "outputId": "f1178509-882e-4333-8da5-96316ac55c5a"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKcKykaDwYMz"
      },
      "source": [
        "class charRNN(nn.Module):\n",
        "  def __init__(self, tokens, hidden_dim = 512, n_layers = 2, drop_prob = 0.5, lr = 0.01):\n",
        "    super().__init__()\n",
        "\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.n_layers = n_layers\n",
        "    self.drop_prob = drop_prob\n",
        "    self.lr = lr\n",
        "\n",
        "    self.chars = tokens\n",
        "    self.int2char = dict(enumerate(self.chars))\n",
        "    self.char2int = {ch:ii for ii, ch in self.int2char.items()}\n",
        "\n",
        "    self.lstm = nn.LSTM(len(self.chars), hidden_dim, n_layers, dropout=drop_prob, batch_first = True)\n",
        "\n",
        "    self.dropout = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    self.fc = nn.Linear(hidden_dim, len(self.chars))\n",
        "  \n",
        "  def forward(self, x, hidden):\n",
        "\n",
        "    output, hidden = self.lstm(x, hidden)\n",
        "\n",
        "    output = self.dropout(output)\n",
        "\n",
        "    output = output.contiguous().view(-1,self.hidden_dim)\n",
        "\n",
        "    output = self.fc(output)\n",
        "\n",
        "    return output, hidden\n",
        "  \n",
        "  def init_hidden(self, batch_size):\n",
        "    weight = next(self.parameters()).data\n",
        "\n",
        "    hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
        "              weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
        "\n",
        "    return hidden"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1PEaXUS4H88"
      },
      "source": [
        "def train(net, data, epochs = 10, batch_size = 10, seq_length = 50, lr = 0.001, clip = 5, val_frac = 0.1, for_every = 10):\n",
        "  net.train()\n",
        "\n",
        "  opt = torch.optim.Adam(net.parameters(), lr = lr)\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  val_idx = int((1-val_frac)*len(data))\n",
        "  data, val_data = data[:val_idx], data[val_idx:]\n",
        "\n",
        "  net.to(device)\n",
        "\n",
        "  counter = 0\n",
        "  n_chars = len(net.chars)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    for x, y in get_batches(data, batch_size, seq_length):\n",
        "      counter += 1\n",
        "\n",
        "      x = one_hot_encode(x, n_chars)\n",
        "\n",
        "      inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
        "\n",
        "      h = tuple([each.data for each in h])\n",
        "\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      outputs, h = net(inputs, h)\n",
        "\n",
        "      loss = criterion(outputs, targets.view(batch_size*seq_length).long())\n",
        "      opt.zero_grad()\n",
        "      loss.backward()\n",
        "      nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "      opt.step()\n",
        "\n",
        "      if counter%for_every == 0:\n",
        "        val_h = net.init_hidden(batch_size)\n",
        "        val_losses = []\n",
        "        net.eval()\n",
        "        for x, y in get_batches(val_data, batch_size, seq_length):\n",
        "          x = one_hot_encode(x, n_chars)\n",
        "          inputs, targets = torch.from_numpy(x).to(device), torch.from_numpy(y).to(device)\n",
        "          val_h = tuple([each.data for each in val_h])\n",
        "          outputs, val_h = net(inputs, val_h)\n",
        "          val_loss = criterion(outputs, targets.view(batch_size*seq_length).long())\n",
        "          val_losses.append(val_loss.item())\n",
        "      \n",
        "        net.train()\n",
        "\n",
        "        print(f\"{epoch+1}/{epochs}, counter = {counter}, train_loss = {loss.item()}, val_loss = {np.mean(val_losses)}\")\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMp0uDidtU70",
        "outputId": "b0dceab1-e528-45e8-84d5-961015a180fd"
      },
      "source": [
        "hidden_dim = 512\n",
        "n_layers = 2\n",
        "\n",
        "# print(hidden_dim)\n",
        "net = charRNN(chars,hidden_dim, n_layers)\n",
        "print(net)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "charRNN(\n",
            "  (lstm): LSTM(83, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=512, out_features=83, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sJIa38etxKf",
        "outputId": "33e01483-3b38-4872-d529-fbdb291dfb68"
      },
      "source": [
        "batch_size = 128\n",
        "seq_length = 100\n",
        "n_epochs = 20\n",
        "\n",
        "train(net, encoded, epochs = n_epochs, batch_size=batch_size, seq_length=seq_length, lr = 0.001)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/20, counter = 10, train_loss = 3.2600297927856445, val_loss = 3.2011275768280028\n",
            "1/20, counter = 20, train_loss = 3.1458301544189453, val_loss = 3.1305514494578044\n",
            "1/20, counter = 30, train_loss = 3.1346373558044434, val_loss = 3.1215799331665037\n",
            "1/20, counter = 40, train_loss = 3.1121761798858643, val_loss = 3.1190361340840655\n",
            "1/20, counter = 50, train_loss = 3.1393866539001465, val_loss = 3.117169189453125\n",
            "1/20, counter = 60, train_loss = 3.1170217990875244, val_loss = 3.1149874210357664\n",
            "1/20, counter = 70, train_loss = 3.106755256652832, val_loss = 3.112496280670166\n",
            "1/20, counter = 80, train_loss = 3.116550922393799, val_loss = 3.1056500752766927\n",
            "1/20, counter = 90, train_loss = 3.1061971187591553, val_loss = 3.090000947316488\n",
            "1/20, counter = 100, train_loss = 3.066688299179077, val_loss = 3.0538565158843993\n",
            "1/20, counter = 110, train_loss = 3.0306363105773926, val_loss = 3.010475524266561\n",
            "1/20, counter = 120, train_loss = 2.97794246673584, val_loss = 2.9088003158569338\n",
            "1/20, counter = 130, train_loss = 2.838923931121826, val_loss = 2.8074694156646727\n",
            "2/20, counter = 140, train_loss = 2.7613027095794678, val_loss = 2.743776003519694\n",
            "2/20, counter = 150, train_loss = 2.666430711746216, val_loss = 2.6033196608225504\n",
            "2/20, counter = 160, train_loss = 2.5704410076141357, val_loss = 2.528788121541341\n",
            "2/20, counter = 170, train_loss = 2.4936094284057617, val_loss = 2.4808101336161297\n",
            "2/20, counter = 180, train_loss = 2.4707775115966797, val_loss = 2.437995497385661\n",
            "2/20, counter = 190, train_loss = 2.4091615676879883, val_loss = 2.404805628458659\n",
            "2/20, counter = 200, train_loss = 2.412938117980957, val_loss = 2.38830680847168\n",
            "2/20, counter = 210, train_loss = 2.3739397525787354, val_loss = 2.348375082015991\n",
            "2/20, counter = 220, train_loss = 2.3370277881622314, val_loss = 2.318984349568685\n",
            "2/20, counter = 230, train_loss = 2.3247690200805664, val_loss = 2.289609368642171\n",
            "2/20, counter = 240, train_loss = 2.3054730892181396, val_loss = 2.2636080106099445\n",
            "2/20, counter = 250, train_loss = 2.244169235229492, val_loss = 2.237320963541667\n",
            "2/20, counter = 260, train_loss = 2.2136831283569336, val_loss = 2.209267234802246\n",
            "2/20, counter = 270, train_loss = 2.2194509506225586, val_loss = 2.1864665349324546\n",
            "3/20, counter = 280, train_loss = 2.2249505519866943, val_loss = 2.165309286117554\n",
            "3/20, counter = 290, train_loss = 2.1781649589538574, val_loss = 2.1453165372212726\n",
            "3/20, counter = 300, train_loss = 2.155839204788208, val_loss = 2.118748156229655\n",
            "3/20, counter = 310, train_loss = 2.1317834854125977, val_loss = 2.102419312795003\n",
            "3/20, counter = 320, train_loss = 2.095902442932129, val_loss = 2.082208029429118\n",
            "3/20, counter = 330, train_loss = 2.077188014984131, val_loss = 2.0673224131266275\n",
            "3/20, counter = 340, train_loss = 2.088280439376831, val_loss = 2.049467754364014\n",
            "3/20, counter = 350, train_loss = 2.064497470855713, val_loss = 2.0296207984288532\n",
            "3/20, counter = 360, train_loss = 1.9986517429351807, val_loss = 2.0111762205759685\n",
            "3/20, counter = 370, train_loss = 2.0303642749786377, val_loss = 1.9961510340372721\n",
            "3/20, counter = 380, train_loss = 2.0053586959838867, val_loss = 1.9783939043680827\n",
            "3/20, counter = 390, train_loss = 1.9833825826644897, val_loss = 1.9654239336649577\n",
            "3/20, counter = 400, train_loss = 1.9477393627166748, val_loss = 1.948116914431254\n",
            "3/20, counter = 410, train_loss = 1.9651153087615967, val_loss = 1.9341492573420207\n",
            "4/20, counter = 420, train_loss = 1.9554030895233154, val_loss = 1.919312834739685\n",
            "4/20, counter = 430, train_loss = 1.9408706426620483, val_loss = 1.9067445596059163\n",
            "4/20, counter = 440, train_loss = 1.9160467386245728, val_loss = 1.8965585629145305\n",
            "4/20, counter = 450, train_loss = 1.8687189817428589, val_loss = 1.8773217439651488\n",
            "4/20, counter = 460, train_loss = 1.8543879985809326, val_loss = 1.8681480487187703\n",
            "4/20, counter = 470, train_loss = 1.8842259645462036, val_loss = 1.854436453183492\n",
            "4/20, counter = 480, train_loss = 1.8632415533065796, val_loss = 1.8416348059972127\n",
            "4/20, counter = 490, train_loss = 1.8658719062805176, val_loss = 1.8289048592249553\n",
            "4/20, counter = 500, train_loss = 1.8625396490097046, val_loss = 1.8223631302515666\n",
            "4/20, counter = 510, train_loss = 1.8346158266067505, val_loss = 1.8108388344446817\n",
            "4/20, counter = 520, train_loss = 1.8542813062667847, val_loss = 1.7999608993530274\n",
            "4/20, counter = 530, train_loss = 1.8100874423980713, val_loss = 1.793381643295288\n",
            "4/20, counter = 540, train_loss = 1.7801008224487305, val_loss = 1.7814005374908448\n",
            "4/20, counter = 550, train_loss = 1.811672329902649, val_loss = 1.770369863510132\n",
            "5/20, counter = 560, train_loss = 1.7817659378051758, val_loss = 1.7562729358673095\n",
            "5/20, counter = 570, train_loss = 1.772451639175415, val_loss = 1.7536648193995157\n",
            "5/20, counter = 580, train_loss = 1.7502092123031616, val_loss = 1.7416938463846843\n",
            "5/20, counter = 590, train_loss = 1.7506970167160034, val_loss = 1.7333300431569418\n",
            "5/20, counter = 600, train_loss = 1.7436184883117676, val_loss = 1.7253562847773234\n",
            "5/20, counter = 610, train_loss = 1.7210524082183838, val_loss = 1.7181374470392863\n",
            "5/20, counter = 620, train_loss = 1.7331054210662842, val_loss = 1.7115716060002646\n",
            "5/20, counter = 630, train_loss = 1.7423133850097656, val_loss = 1.7024910847345989\n",
            "5/20, counter = 640, train_loss = 1.7042306661605835, val_loss = 1.6969399611155191\n",
            "5/20, counter = 650, train_loss = 1.6958203315734863, val_loss = 1.6890918572743734\n",
            "5/20, counter = 660, train_loss = 1.6743944883346558, val_loss = 1.6815489053726196\n",
            "5/20, counter = 670, train_loss = 1.6937609910964966, val_loss = 1.6779219388961792\n",
            "5/20, counter = 680, train_loss = 1.6915011405944824, val_loss = 1.6671327273050944\n",
            "5/20, counter = 690, train_loss = 1.664870023727417, val_loss = 1.660397219657898\n",
            "6/20, counter = 700, train_loss = 1.6657066345214844, val_loss = 1.6531481424967447\n",
            "6/20, counter = 710, train_loss = 1.6627851724624634, val_loss = 1.6477224191029867\n",
            "6/20, counter = 720, train_loss = 1.6548385620117188, val_loss = 1.6413693348566691\n",
            "6/20, counter = 730, train_loss = 1.6566141843795776, val_loss = 1.6337762117385863\n",
            "6/20, counter = 740, train_loss = 1.6319172382354736, val_loss = 1.6281371116638184\n",
            "6/20, counter = 750, train_loss = 1.6153804063796997, val_loss = 1.6306922833124797\n",
            "6/20, counter = 760, train_loss = 1.6495578289031982, val_loss = 1.6205085913340251\n",
            "6/20, counter = 770, train_loss = 1.6304861307144165, val_loss = 1.6142857154210408\n",
            "6/20, counter = 780, train_loss = 1.6031156778335571, val_loss = 1.6084978659947713\n",
            "6/20, counter = 790, train_loss = 1.5957014560699463, val_loss = 1.6013751745223999\n",
            "6/20, counter = 800, train_loss = 1.6134947538375854, val_loss = 1.6011719385782877\n",
            "6/20, counter = 810, train_loss = 1.5954393148422241, val_loss = 1.5942192475001018\n",
            "6/20, counter = 820, train_loss = 1.5638132095336914, val_loss = 1.588305942217509\n",
            "6/20, counter = 830, train_loss = 1.607593059539795, val_loss = 1.5841599225997924\n",
            "7/20, counter = 840, train_loss = 1.5684776306152344, val_loss = 1.5769893964131674\n",
            "7/20, counter = 850, train_loss = 1.5852851867675781, val_loss = 1.573511799176534\n",
            "7/20, counter = 860, train_loss = 1.570947289466858, val_loss = 1.5688560088475545\n",
            "7/20, counter = 870, train_loss = 1.5679962635040283, val_loss = 1.565076486269633\n",
            "7/20, counter = 880, train_loss = 1.5798832178115845, val_loss = 1.5594847758611043\n",
            "7/20, counter = 890, train_loss = 1.569352626800537, val_loss = 1.5566423972447714\n",
            "7/20, counter = 900, train_loss = 1.55910325050354, val_loss = 1.5532217582066854\n",
            "7/20, counter = 910, train_loss = 1.526254415512085, val_loss = 1.550852155685425\n",
            "7/20, counter = 920, train_loss = 1.5376641750335693, val_loss = 1.544129776954651\n",
            "7/20, counter = 930, train_loss = 1.526416301727295, val_loss = 1.5391754945119223\n",
            "7/20, counter = 940, train_loss = 1.543718695640564, val_loss = 1.5380029757817586\n",
            "7/20, counter = 950, train_loss = 1.5408761501312256, val_loss = 1.532523242632548\n",
            "7/20, counter = 960, train_loss = 1.5467103719711304, val_loss = 1.5307307879130045\n",
            "7/20, counter = 970, train_loss = 1.54301118850708, val_loss = 1.5253048022588094\n",
            "8/20, counter = 980, train_loss = 1.525295615196228, val_loss = 1.5189010461171468\n",
            "8/20, counter = 990, train_loss = 1.5145277976989746, val_loss = 1.5169715245564779\n",
            "8/20, counter = 1000, train_loss = 1.510452389717102, val_loss = 1.5137760798136393\n",
            "8/20, counter = 1010, train_loss = 1.548059344291687, val_loss = 1.5129531462987265\n",
            "8/20, counter = 1020, train_loss = 1.515753984451294, val_loss = 1.5095858176549275\n",
            "8/20, counter = 1030, train_loss = 1.499558925628662, val_loss = 1.5069310665130615\n",
            "8/20, counter = 1040, train_loss = 1.5134555101394653, val_loss = 1.5056821823120117\n",
            "8/20, counter = 1050, train_loss = 1.4884284734725952, val_loss = 1.4998163064320882\n",
            "8/20, counter = 1060, train_loss = 1.500503420829773, val_loss = 1.4985852003097535\n",
            "8/20, counter = 1070, train_loss = 1.504044771194458, val_loss = 1.4932044585545858\n",
            "8/20, counter = 1080, train_loss = 1.4916322231292725, val_loss = 1.4902523120244344\n",
            "8/20, counter = 1090, train_loss = 1.4773533344268799, val_loss = 1.48595871925354\n",
            "8/20, counter = 1100, train_loss = 1.46895170211792, val_loss = 1.4847219387690227\n",
            "8/20, counter = 1110, train_loss = 1.4845013618469238, val_loss = 1.480353021621704\n",
            "9/20, counter = 1120, train_loss = 1.490473747253418, val_loss = 1.4772855281829833\n",
            "9/20, counter = 1130, train_loss = 1.489247441291809, val_loss = 1.4755939483642577\n",
            "9/20, counter = 1140, train_loss = 1.481355905532837, val_loss = 1.4701011896133422\n",
            "9/20, counter = 1150, train_loss = 1.4950145483016968, val_loss = 1.4731235106786091\n",
            "9/20, counter = 1160, train_loss = 1.4527450799942017, val_loss = 1.4685473442077637\n",
            "9/20, counter = 1170, train_loss = 1.460646629333496, val_loss = 1.4670453389485678\n",
            "9/20, counter = 1180, train_loss = 1.4577889442443848, val_loss = 1.468251848220825\n",
            "9/20, counter = 1190, train_loss = 1.4955472946166992, val_loss = 1.4637385129928588\n",
            "9/20, counter = 1200, train_loss = 1.4353986978530884, val_loss = 1.4598951101303101\n",
            "9/20, counter = 1210, train_loss = 1.4474612474441528, val_loss = 1.4543537457784017\n",
            "9/20, counter = 1220, train_loss = 1.4450194835662842, val_loss = 1.454930098851522\n",
            "9/20, counter = 1230, train_loss = 1.4304025173187256, val_loss = 1.4505160093307494\n",
            "9/20, counter = 1240, train_loss = 1.4363311529159546, val_loss = 1.4469639778137207\n",
            "9/20, counter = 1250, train_loss = 1.4312667846679688, val_loss = 1.4474983215332031\n",
            "10/20, counter = 1260, train_loss = 1.443660020828247, val_loss = 1.4437968730926514\n",
            "10/20, counter = 1270, train_loss = 1.4394824504852295, val_loss = 1.4424363533655802\n",
            "10/20, counter = 1280, train_loss = 1.4518617391586304, val_loss = 1.4402063369750977\n",
            "10/20, counter = 1290, train_loss = 1.441019892692566, val_loss = 1.4409097671508788\n",
            "10/20, counter = 1300, train_loss = 1.4300994873046875, val_loss = 1.4394168774286906\n",
            "10/20, counter = 1310, train_loss = 1.4333927631378174, val_loss = 1.437012497584025\n",
            "10/20, counter = 1320, train_loss = 1.405018925666809, val_loss = 1.4336570024490356\n",
            "10/20, counter = 1330, train_loss = 1.4160996675491333, val_loss = 1.431394060452779\n",
            "10/20, counter = 1340, train_loss = 1.4004932641983032, val_loss = 1.4298819224039714\n",
            "10/20, counter = 1350, train_loss = 1.3955047130584717, val_loss = 1.423076876004537\n",
            "10/20, counter = 1360, train_loss = 1.3926295042037964, val_loss = 1.4230030139287313\n",
            "10/20, counter = 1370, train_loss = 1.395239233970642, val_loss = 1.4201236963272095\n",
            "10/20, counter = 1380, train_loss = 1.4309782981872559, val_loss = 1.4173371553421021\n",
            "10/20, counter = 1390, train_loss = 1.4420373439788818, val_loss = 1.4194382111231485\n",
            "11/20, counter = 1400, train_loss = 1.4349067211151123, val_loss = 1.4160189469655355\n",
            "11/20, counter = 1410, train_loss = 1.4451384544372559, val_loss = 1.416598121325175\n",
            "11/20, counter = 1420, train_loss = 1.4349228143692017, val_loss = 1.412427576382955\n",
            "11/20, counter = 1430, train_loss = 1.4056122303009033, val_loss = 1.4129357576370238\n",
            "11/20, counter = 1440, train_loss = 1.4328699111938477, val_loss = 1.4119063059488932\n",
            "11/20, counter = 1450, train_loss = 1.3508833646774292, val_loss = 1.410453494389852\n",
            "11/20, counter = 1460, train_loss = 1.392628788948059, val_loss = 1.4068120082219442\n",
            "11/20, counter = 1470, train_loss = 1.3759269714355469, val_loss = 1.405653476715088\n",
            "11/20, counter = 1480, train_loss = 1.396671175956726, val_loss = 1.402249519030253\n",
            "11/20, counter = 1490, train_loss = 1.3842649459838867, val_loss = 1.4010987599690756\n",
            "11/20, counter = 1500, train_loss = 1.3682217597961426, val_loss = 1.4037869612375895\n",
            "11/20, counter = 1510, train_loss = 1.3569731712341309, val_loss = 1.3988103866577148\n",
            "11/20, counter = 1520, train_loss = 1.401273488998413, val_loss = 1.398089623451233\n",
            "12/20, counter = 1530, train_loss = 1.4384143352508545, val_loss = 1.3963429133097331\n",
            "12/20, counter = 1540, train_loss = 1.392602801322937, val_loss = 1.3935547431310018\n",
            "12/20, counter = 1550, train_loss = 1.4041084051132202, val_loss = 1.3961185057957968\n",
            "12/20, counter = 1560, train_loss = 1.4150798320770264, val_loss = 1.390141455332438\n",
            "12/20, counter = 1570, train_loss = 1.3625056743621826, val_loss = 1.391587257385254\n",
            "12/20, counter = 1580, train_loss = 1.3272570371627808, val_loss = 1.3871333440144857\n",
            "12/20, counter = 1590, train_loss = 1.3394267559051514, val_loss = 1.3875753243764242\n",
            "12/20, counter = 1600, train_loss = 1.3606709241867065, val_loss = 1.384896469116211\n",
            "12/20, counter = 1610, train_loss = 1.34804368019104, val_loss = 1.3868956327438355\n",
            "12/20, counter = 1620, train_loss = 1.3505587577819824, val_loss = 1.3835489590962728\n",
            "12/20, counter = 1630, train_loss = 1.360825538635254, val_loss = 1.3828492959340413\n",
            "12/20, counter = 1640, train_loss = 1.3401309251785278, val_loss = 1.3854220628738403\n",
            "12/20, counter = 1650, train_loss = 1.3192107677459717, val_loss = 1.3792682568232217\n",
            "12/20, counter = 1660, train_loss = 1.3769466876983643, val_loss = 1.3768757422765097\n",
            "13/20, counter = 1670, train_loss = 1.3482906818389893, val_loss = 1.377248430252075\n",
            "13/20, counter = 1680, train_loss = 1.3568620681762695, val_loss = 1.3714416742324829\n",
            "13/20, counter = 1690, train_loss = 1.334362506866455, val_loss = 1.3719022035598756\n",
            "13/20, counter = 1700, train_loss = 1.3356987237930298, val_loss = 1.3694829225540162\n",
            "13/20, counter = 1710, train_loss = 1.3299938440322876, val_loss = 1.3708828608194987\n",
            "13/20, counter = 1720, train_loss = 1.3292269706726074, val_loss = 1.3707395712534587\n",
            "13/20, counter = 1730, train_loss = 1.3746001720428467, val_loss = 1.368003543217977\n",
            "13/20, counter = 1740, train_loss = 1.3374868631362915, val_loss = 1.3679277976353963\n",
            "13/20, counter = 1750, train_loss = 1.3046339750289917, val_loss = 1.3688758214314778\n",
            "13/20, counter = 1760, train_loss = 1.333247184753418, val_loss = 1.3641265312830606\n",
            "13/20, counter = 1770, train_loss = 1.3426933288574219, val_loss = 1.3649109760920206\n",
            "13/20, counter = 1780, train_loss = 1.3230818510055542, val_loss = 1.365681521097819\n",
            "13/20, counter = 1790, train_loss = 1.3177647590637207, val_loss = 1.3595893541971842\n",
            "13/20, counter = 1800, train_loss = 1.3367120027542114, val_loss = 1.3586026112238565\n",
            "14/20, counter = 1810, train_loss = 1.3372422456741333, val_loss = 1.363169535001119\n",
            "14/20, counter = 1820, train_loss = 1.3327205181121826, val_loss = 1.3540363788604737\n",
            "14/20, counter = 1830, train_loss = 1.339035987854004, val_loss = 1.3530324935913085\n",
            "14/20, counter = 1840, train_loss = 1.2966053485870361, val_loss = 1.3520010550816854\n",
            "14/20, counter = 1850, train_loss = 1.2769042253494263, val_loss = 1.3529947598775227\n",
            "14/20, counter = 1860, train_loss = 1.3332154750823975, val_loss = 1.3478078842163086\n",
            "14/20, counter = 1870, train_loss = 1.3345028162002563, val_loss = 1.350618632634481\n",
            "14/20, counter = 1880, train_loss = 1.3269801139831543, val_loss = 1.3471936066945394\n",
            "14/20, counter = 1890, train_loss = 1.3490501642227173, val_loss = 1.3520716826121013\n",
            "14/20, counter = 1900, train_loss = 1.3145344257354736, val_loss = 1.3426286220550536\n",
            "14/20, counter = 1910, train_loss = 1.319872260093689, val_loss = 1.3454245249430339\n",
            "14/20, counter = 1920, train_loss = 1.3141690492630005, val_loss = 1.342593010266622\n",
            "14/20, counter = 1930, train_loss = 1.2800520658493042, val_loss = 1.3439856926600138\n",
            "14/20, counter = 1940, train_loss = 1.341431736946106, val_loss = 1.3404923995335898\n",
            "15/20, counter = 1950, train_loss = 1.3082760572433472, val_loss = 1.3383387724558513\n",
            "15/20, counter = 1960, train_loss = 1.3035317659378052, val_loss = 1.3335554758707682\n",
            "15/20, counter = 1970, train_loss = 1.2949180603027344, val_loss = 1.335045329729716\n",
            "15/20, counter = 1980, train_loss = 1.2842084169387817, val_loss = 1.3347464799880981\n",
            "15/20, counter = 1990, train_loss = 1.2950563430786133, val_loss = 1.332522694269816\n",
            "15/20, counter = 2000, train_loss = 1.278184413909912, val_loss = 1.3327910582224527\n",
            "15/20, counter = 2010, train_loss = 1.3004108667373657, val_loss = 1.3272359689076743\n",
            "15/20, counter = 2020, train_loss = 1.3214771747589111, val_loss = 1.3332210381825764\n",
            "15/20, counter = 2030, train_loss = 1.2882676124572754, val_loss = 1.3320673942565917\n",
            "15/20, counter = 2040, train_loss = 1.2831480503082275, val_loss = 1.3304171244303384\n",
            "15/20, counter = 2050, train_loss = 1.2780075073242188, val_loss = 1.3314205249150595\n",
            "15/20, counter = 2060, train_loss = 1.2886948585510254, val_loss = 1.3330487410227458\n",
            "15/20, counter = 2070, train_loss = 1.298863410949707, val_loss = 1.3223069588343301\n",
            "15/20, counter = 2080, train_loss = 1.2829934358596802, val_loss = 1.319938333829244\n",
            "16/20, counter = 2090, train_loss = 1.3039042949676514, val_loss = 1.3197136561075846\n",
            "16/20, counter = 2100, train_loss = 1.2804467678070068, val_loss = 1.3156195481618245\n",
            "16/20, counter = 2110, train_loss = 1.2641264200210571, val_loss = 1.3218377669652304\n",
            "16/20, counter = 2120, train_loss = 1.2968318462371826, val_loss = 1.3196158250172934\n",
            "16/20, counter = 2130, train_loss = 1.2631722688674927, val_loss = 1.3172423044840496\n",
            "16/20, counter = 2140, train_loss = 1.255751609802246, val_loss = 1.3171871503194172\n",
            "16/20, counter = 2150, train_loss = 1.3006445169448853, val_loss = 1.3207102060317992\n",
            "16/20, counter = 2160, train_loss = 1.2680141925811768, val_loss = 1.3177664915720622\n",
            "16/20, counter = 2170, train_loss = 1.2724021673202515, val_loss = 1.3155717690785727\n",
            "16/20, counter = 2180, train_loss = 1.2643235921859741, val_loss = 1.3157607237497966\n",
            "16/20, counter = 2190, train_loss = 1.2795648574829102, val_loss = 1.313124457995097\n",
            "16/20, counter = 2200, train_loss = 1.261217474937439, val_loss = 1.3115408102671304\n",
            "16/20, counter = 2210, train_loss = 1.2307076454162598, val_loss = 1.3182136138280234\n",
            "16/20, counter = 2220, train_loss = 1.2788879871368408, val_loss = 1.3119867086410522\n",
            "17/20, counter = 2230, train_loss = 1.2541736364364624, val_loss = 1.3078661998112997\n",
            "17/20, counter = 2240, train_loss = 1.2573399543762207, val_loss = 1.3059035857518515\n",
            "17/20, counter = 2250, train_loss = 1.2362663745880127, val_loss = 1.3098543961842855\n",
            "17/20, counter = 2260, train_loss = 1.2565600872039795, val_loss = 1.3073353052139283\n",
            "17/20, counter = 2270, train_loss = 1.2642676830291748, val_loss = 1.3033989032109579\n",
            "17/20, counter = 2280, train_loss = 1.2595136165618896, val_loss = 1.306085467338562\n",
            "17/20, counter = 2290, train_loss = 1.2647204399108887, val_loss = 1.3150494257609049\n",
            "17/20, counter = 2300, train_loss = 1.226779818534851, val_loss = 1.3090027968088787\n",
            "17/20, counter = 2310, train_loss = 1.2513606548309326, val_loss = 1.309600798288981\n",
            "17/20, counter = 2320, train_loss = 1.2428864240646362, val_loss = 1.3134868621826172\n",
            "17/20, counter = 2330, train_loss = 1.2504557371139526, val_loss = 1.3092382033665975\n",
            "17/20, counter = 2340, train_loss = 1.2648576498031616, val_loss = 1.2976523081461588\n",
            "17/20, counter = 2350, train_loss = 1.2664382457733154, val_loss = 1.2982878049214681\n",
            "17/20, counter = 2360, train_loss = 1.2671793699264526, val_loss = 1.307617735862732\n",
            "18/20, counter = 2370, train_loss = 1.2394167184829712, val_loss = 1.3037304480870564\n",
            "18/20, counter = 2380, train_loss = 1.2539305686950684, val_loss = 1.2968074083328247\n",
            "18/20, counter = 2390, train_loss = 1.2530097961425781, val_loss = 1.300790254275004\n",
            "18/20, counter = 2400, train_loss = 1.2712340354919434, val_loss = 1.2967013597488404\n",
            "18/20, counter = 2410, train_loss = 1.2655731439590454, val_loss = 1.297642739613851\n",
            "18/20, counter = 2420, train_loss = 1.2472952604293823, val_loss = 1.2964846690495808\n",
            "18/20, counter = 2430, train_loss = 1.2503079175949097, val_loss = 1.3050788482030233\n",
            "18/20, counter = 2440, train_loss = 1.2331708669662476, val_loss = 1.297967012723287\n",
            "18/20, counter = 2450, train_loss = 1.2230699062347412, val_loss = 1.295116392771403\n",
            "18/20, counter = 2460, train_loss = 1.2535786628723145, val_loss = 1.2911827564239502\n",
            "18/20, counter = 2470, train_loss = 1.2466048002243042, val_loss = 1.2990918318430582\n",
            "18/20, counter = 2480, train_loss = 1.2285375595092773, val_loss = 1.3042367458343507\n",
            "18/20, counter = 2490, train_loss = 1.2281720638275146, val_loss = 1.293757700920105\n",
            "18/20, counter = 2500, train_loss = 1.2281792163848877, val_loss = 1.2950230757395427\n",
            "19/20, counter = 2510, train_loss = 1.2362278699874878, val_loss = 1.2905748923619589\n",
            "19/20, counter = 2520, train_loss = 1.2433362007141113, val_loss = 1.2881336768468221\n",
            "19/20, counter = 2530, train_loss = 1.2596832513809204, val_loss = 1.2925893545150757\n",
            "19/20, counter = 2540, train_loss = 1.2593847513198853, val_loss = 1.2921031951904296\n",
            "19/20, counter = 2550, train_loss = 1.2260942459106445, val_loss = 1.28831840356191\n",
            "19/20, counter = 2560, train_loss = 1.2445623874664307, val_loss = 1.2863920132319133\n",
            "19/20, counter = 2570, train_loss = 1.227880597114563, val_loss = 1.2880534092585245\n",
            "19/20, counter = 2580, train_loss = 1.2605468034744263, val_loss = 1.2868350982666015\n",
            "19/20, counter = 2590, train_loss = 1.2238353490829468, val_loss = 1.2842915534973145\n",
            "19/20, counter = 2600, train_loss = 1.2157790660858154, val_loss = 1.2816235462824503\n",
            "19/20, counter = 2610, train_loss = 1.2258964776992798, val_loss = 1.2881251414616903\n",
            "19/20, counter = 2620, train_loss = 1.20604407787323, val_loss = 1.2822911421457925\n",
            "19/20, counter = 2630, train_loss = 1.2125601768493652, val_loss = 1.282375733057658\n",
            "19/20, counter = 2640, train_loss = 1.239180088043213, val_loss = 1.2884768486022948\n",
            "20/20, counter = 2650, train_loss = 1.2292946577072144, val_loss = 1.2854652325312297\n",
            "20/20, counter = 2660, train_loss = 1.2310740947723389, val_loss = 1.282530967394511\n",
            "20/20, counter = 2670, train_loss = 1.2420399188995361, val_loss = 1.280865240097046\n",
            "20/20, counter = 2680, train_loss = 1.2348054647445679, val_loss = 1.2792683839797974\n",
            "20/20, counter = 2690, train_loss = 1.2218585014343262, val_loss = 1.2808662176132202\n",
            "20/20, counter = 2700, train_loss = 1.2342100143432617, val_loss = 1.2788860559463502\n",
            "20/20, counter = 2710, train_loss = 1.1971447467803955, val_loss = 1.2796796878178915\n",
            "20/20, counter = 2720, train_loss = 1.198960304260254, val_loss = 1.2821582953135173\n",
            "20/20, counter = 2730, train_loss = 1.196520209312439, val_loss = 1.277239998181661\n",
            "20/20, counter = 2740, train_loss = 1.1960796117782593, val_loss = 1.2758751392364502\n",
            "20/20, counter = 2750, train_loss = 1.202605128288269, val_loss = 1.2809529860814413\n",
            "20/20, counter = 2760, train_loss = 1.2023823261260986, val_loss = 1.2781930923461915\n",
            "20/20, counter = 2770, train_loss = 1.2405877113342285, val_loss = 1.276869503657023\n",
            "20/20, counter = 2780, train_loss = 1.2529000043869019, val_loss = 1.2791198253631593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXWlEdlDu84v"
      },
      "source": [
        "model_name = \"rnn_20_epoch_charRNN.net\"\n",
        "\n",
        "checkpoint = {\n",
        "    'hidden_dim':net.hidden_dim,\n",
        "    'n_layers':net.n_layers,\n",
        "    'state_dict':net.state_dict(),\n",
        "    'tokens':net.chars\n",
        "}"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWyCgWsQUkS_"
      },
      "source": [
        "with open(model_name, 'wb') as f:\n",
        "  torch.save(checkpoint, f)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CIJfglKYHbH"
      },
      "source": [
        "model = torch.load(model_name)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-GwaSpdYTWm"
      },
      "source": [
        "def predict(net, char, h = None, top_k = None):\n",
        "  net.to(device)\n",
        "\n",
        "  h = tuple([each.data for each in h])\n",
        "\n",
        "  inp = np.array([[net.char2int[char]]])\n",
        "  inp = one_hot_encode(inp, len(net.chars))\n",
        "\n",
        "  inp = torch.from_numpy(inp)\n",
        "\n",
        "  inp = inp.to(device)\n",
        "\n",
        "  \n",
        "  out, h = net(inp, h)\n",
        "  \n",
        "  p = torch.nn.functional.softmax(out, dim=1).data\n",
        "\n",
        "  p = p.cpu()\n",
        "\n",
        "  if top_k is None:\n",
        "    top_ch = np.arange(len(net.chars))\n",
        "  else:\n",
        "    p, top_ch = p.topk(top_k)\n",
        "    top_ch = top_ch.numpy().squeeze()\n",
        "  \n",
        "  p = p.numpy().squeeze()\n",
        "  char = np.random.choice(top_ch, p = p/p.sum())\n",
        "\n",
        "  return net.int2char[char], h"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etTLrSqpcR_q"
      },
      "source": [
        "def sample(net, size, prime = \"The\", top_k = None):\n",
        "  net.to(device)\n",
        "\n",
        "  chars = [ch for ch in prime]\n",
        "\n",
        "  net.eval()\n",
        "  \n",
        "  h = net.init_hidden(1)\n",
        "\n",
        "  for ch in prime:\n",
        "    char, h = predict(net, ch, h, top_k=top_k)\n",
        "  \n",
        "  chars.append(char)\n",
        "\n",
        "  for ii in range(size):\n",
        "    char, h = predict(net, chars[-1], h, top_k=top_k)\n",
        "    chars.append(char)\n",
        "  \n",
        "  return ''.join(chars)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2yE84AdehGB",
        "outputId": "e481b72c-3644-4b6e-ebf8-069ce9fe20f6"
      },
      "source": [
        "print(sample(net, 500, prime = \"Anna\", top_k = 5))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Anna's, that\n",
            "there was nothing to go to him. The sight of anything she could not come on\n",
            "all her ten thing, but the setsed conversation of the\n",
            "candle, then talking on the crowd as the money them had been a\n",
            "good-nut one to him, and they saw that his bride stour\n",
            "she saw the sound and supple arressing the priest, who had\n",
            "been busines, and\n",
            "suppositively was not seeming, and he had standed out the sight and\n",
            "things, he felt her husband to see his hands were the second\n",
            "condition, his face too hade and ask i\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gs8ybHwie7kF",
        "outputId": "cb7582c9-6a6d-47c1-f530-ee07c722957e"
      },
      "source": [
        "print(sample(net, 500, prime = \"Vathsa\", top_k = 5))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vathsa,\" said\n",
            "Levin.\n",
            "\n",
            "\"Well, the chances of your face of the sort of terrible arouses in\n",
            "his fruchlin, though, to that is they are, what I was standing and\n",
            "tensters as the minutes, was in the state, but the most mosers for the\n",
            "sour of her fact it are more into them, was a little again.\"\n",
            "\n",
            "Alexey Alexandrovitch smedled as his face, was as how to be\n",
            "service. Her hands almost come at the better of the story, was\n",
            "as it all the prince. He can off on his brother, he felt that the princess\n",
            "saw the same thing w\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9XUcmahfOrU",
        "outputId": "fdd25e24-4c95-4f02-90d9-a67b357796ac"
      },
      "source": [
        "with open(\"rnn_20_epoch_charRNN.net\", \"rb\") as f:\n",
        "  checkpoint = torch.load(f)\n",
        "\n",
        "loaded = charRNN(checkpoint[\"tokens\"] ,hidden_dim = checkpoint[\"hidden_dim\"], n_layers = checkpoint[\"n_layers\"])\n",
        "loaded.load_state_dict(checkpoint[\"state_dict\"])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5mPfWPJgDSw",
        "outputId": "2f31ab4c-3a2b-48a1-b898-c6d4cca5d539"
      },
      "source": [
        "print(sample(loaded, 500, 'Dara', top_k = 5))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Daral\n",
            "Stepan Arkadyevitch, but at him till she had taken a strange time, and the\n",
            "counting mare was at that moment with his way all that. The dropped he\n",
            "had taken under the department with her. She stopped him. They\n",
            "could not hear some starches with a legter. He could not have to say in\n",
            "speaking, and their conversation, and threw happiness, and\n",
            "his face was to tried. Still he had been discassed on the corn in\n",
            "the marsh of them, and and she was daightering that the\n",
            "servants of the morness of their posi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLzh3CWQgPTj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}